{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f812e0-03a5-4321-9792-0006eb610f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from PIL import Image\n",
    "from math import exp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from CBD.utils.resnet import resnet20\n",
    "from CBD.utils.vgg import vgg16\n",
    "from CBD.utils.mobilenetv2 import mobilenetv2\n",
    "from GuidedDiffusionPur.guided_diffusion.script_util import (\n",
    "    model_and_diffusion_defaults,\n",
    "    create_model_and_diffusion,\n",
    "    args_to_dict,\n",
    ")\n",
    "from GuidedDiffusionPur.pytorch_diffusion.diffusion import Diffusion\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bba78bd-11ab-4032-9262-59a01941a074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root='../../../pk-data-4T/cifar10/train', \n",
    "                            transform=transforms.Compose([\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomCrop(32, 4),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261]),\n",
    "                                ]))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "test_dataset = ImageFolder(root='../../../pk-data-4T/cifar10/test', \n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261])\n",
    "                            ]))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343da8c7-5a45-47c8-9c27-379c2a33c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet20().to(device)\n",
    "# model = vgg16().to(device)\n",
    "# model = mobilenetv2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a1cc09-911b-47e8-bcdb-cefe44d78279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=torch.tensor([100, 150]).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b7b12-288a-47c9-b68e-7afcb3fbc643",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for (images, labels) in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            accuracy = 100 * correct / total\n",
    "    print('Epoch:%d, Accuracy on the test set: %.1f %%' % (epoch, accuracy))\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), './FBA/model/cifar10_resnet20.pth')\n",
    "        # torch.save(model.state_dict(), './FBA/model/cifar10_vgg16.pth')\n",
    "        # torch.save(model.state_dict(), './FBA/model/cifar10_mobilenetv2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a7c5e-2301-4b76-ac6a-02948d4b00bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diffusion = Diffusion.from_pretrained(name='ema_cifar10', device=device)\n",
    "\n",
    "transform_normalize = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261])\n",
    "\n",
    "def sample_cifar10(inputs, max_iter, diffusion, t_steps, cond, guide_mode, model):\n",
    "    def cond_fn(inputs_reverse_t, t):\n",
    "        with torch.enable_grad():\n",
    "            inputs_in = inputs_reverse_t.detach().requires_grad_(True)\n",
    "            inputs_out_t = inputs\n",
    "            # inputs_out_t = diffusion.diffuse_t_steps(inputs, t)\n",
    "            if guide_mode == 'MSE': \n",
    "                selected = -1 * F.mse_loss(inputs_in, inputs_out_t)\n",
    "                scale = diffusion.compute_scale(inputs_in, t, 8.0*2/255. / 3. / 60000)\n",
    "            elif guide_mode == 'SSIM':\n",
    "                selected = pytorch_ssim.ssim(inputs_in, inputs_out_t)\n",
    "                scale = diffusion.compute_scale(inputs_in, t, 8.0*2/255. / 3. / 70000)\n",
    "            elif guide_mode == 'LPIPS':\n",
    "                _, feature_21, feature_31, feature_41 = model.forward(transform_normalize(inputs_in), return_hidden=False, return_activation=True)\n",
    "                _, feature_22, feature_32, feature_42 = model.forward(transform_normalize(inputs_out_t), return_hidden=False, return_activation=True)\n",
    "                \n",
    "                min_value = torch.min(feature_22).item()\n",
    "                max_value = torch.max(feature_22).item()\n",
    "                median_value = (min_value + max_value)/2.0\n",
    "                \n",
    "                feature_22[feature_22 > median_value] += (median_value/10.0)\n",
    "                feature_22[feature_22 < median_value] -= (median_value/10.0)\n",
    "                feature_22 = torch.clamp(feature_22, min_value, max_value)\n",
    "                                \n",
    "                selected = -1.0*torch.mean((feature_21 - feature_22)**2)\n",
    "                scale = diffusion.compute_scale(inputs_in, t, 8.0*2/255. / 3. / 10000)\n",
    "            elif guide_mode == 'CONSTANT': \n",
    "                scale = 50000\n",
    "            return torch.autograd.grad(selected.sum(), inputs_in)[0] * scale\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs_t_reverse = inputs\n",
    "        for i in range(max_iter):            \n",
    "            inputs_t = diffusion.diffuse_t_steps(inputs_t_reverse, t_steps)\n",
    "            inputs_t_reverse = diffusion.denoise(\n",
    "                inputs_t.shape[0], \n",
    "                n_steps=t_steps, \n",
    "                x=inputs_t, \n",
    "                curr_step=t_steps, \n",
    "                cond_fn = cond_fn if cond else None\n",
    "            )\n",
    "        images = inputs_t_reverse.clone().detach()\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e652f-c4a6-4426-9539-bdb25080783c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root='../../../pk-data-4T/cifar10_poison/train', \n",
    "                            transform=transforms.Compose([\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomCrop(32, 4),\n",
    "                                    transforms.ToTensor(),\n",
    "                                ]))\n",
    "\n",
    "test_dataset = ImageFolder(root='../../../pk-data-4T/cifar10_poison/test', \n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dab188f-ac92-457d-bb11-6d861f86ab3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = '../../../pk-data-4T/cifar10_poison/train_poison/0'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    image, label = train_dataset[i]\n",
    "    output = sample_cifar10(inputs=image.unsqueeze(0).to(device), \n",
    "                            max_iter=1, \n",
    "                            diffusion=diffusion, \n",
    "                            t_steps=20, \n",
    "                            cond=True, \n",
    "                            guide_mode='LPIPS', \n",
    "                            model=model.eval().to(device))\n",
    "    image_pil = transforms.ToPILImage()(output[0].cpu())\n",
    "    image_pil.save(os.path.join(output_dir, f'cifar10_train_poison_image_{i}.png'))\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf5540-72db-4a4c-afd4-246747d8224c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = '../../../pk-data-4T/cifar10_poison/test_poison'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    image, label = test_dataset[i]\n",
    "    output = sample_cifar10(inputs=image.unsqueeze(0).to(device), \n",
    "                            max_iter=1, \n",
    "                            diffusion=diffusion, \n",
    "                            t_steps=20, \n",
    "                            cond=True, \n",
    "                            guide_mode='LPIPS', \n",
    "                            model=model.eval().to(device)) \n",
    "    class_dir = os.path.join(output_dir, str(label))\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "    image_pil = transforms.ToPILImage()(output[0].cpu())\n",
    "    image_pil.save(os.path.join(class_dir, f'cifar10_test_poison_image_{i}.png'))\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f29b83-bf20-47ce-9760-2795492976d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root='../../../pk-data-4T/cifar10_poison/train_poison', \n",
    "                            transform=transforms.Compose([\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomCrop(32, 4),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261]),\n",
    "                                ]))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "test_dataset = ImageFolder(root='../../../pk-data-4T/cifar10_poison/test', \n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261])\n",
    "                            ]))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "test_dataset_poisoned = ImageFolder(root='../../../pk-data-4T/cifar10_poison/test_poison', \n",
    "                            transform=transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261])\n",
    "                            ]))\n",
    "\n",
    "test_loader_poisoned = DataLoader(test_dataset_poisoned, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf40441-97b3-406b-85fc-c661ef6b0bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=torch.tensor([100, 150]).tolist())\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "best_accuracy = 0.0\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for (images, labels) in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            accuracy = 100 * correct / total\n",
    "    print('Epoch:%d, Clean Accuracy on the test set: %.1f %%' % (epoch, accuracy))\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for (images, _) in test_loader_poisoned:\n",
    "            labels = torch.full((images.shape[0],), 0, dtype=torch.long)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            accuracy = 100 * correct / total\n",
    "    print('Epoch:%d, Poisoned Accuracy on the test set: %.1f %%' % (epoch, accuracy))\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), './FBA/model/cifar10_resnet20_poison.pth')\n",
    "        # torch.save(model.state_dict(), './FBA/model/cifar10_vgg16_poison.pth')\n",
    "        # torch.save(model.state_dict(), './FBA/model/cifar10_mobilenetv2_poison.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
